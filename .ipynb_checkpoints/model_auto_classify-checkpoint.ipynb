{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas import Series, DataFrame\n",
    "from sklearn.decomposition import PCA \n",
    "from sklearn.preprocessing import normalize\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import RMSprop\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data\n",
    "dataset is [datax, datay]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "datax = pd.read_csv('../feature.csv', sep='\\t')\n",
    "datay = pd.read_csv('output_y.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge x and y, and drop NA\n",
    "pd_data = pd.concat([datax,datay],axis=1)\n",
    "pd_data = pd_data.dropna(axis=0, how='any') \n",
    "#Remove bad data\n",
    "pd_data = pd_data[~pd_data['discount_rate'].isin(['販売価格'])]\n",
    "pd_data = pd_data[~pd_data['discount_rate'].isin(['ダミー'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = pd_data[['deal_category_cd','shop_id','deal_type_cd','deal_price','discount_rate','month','duration_days']]\n",
    "data2 = pd_data.drop(['deal_category_cd','shop_id','deal_type_cd','deal_price','discount_rate','month','duration_days'], axis=1)\n",
    "data1 = normalize(data1, axis=0, norm='max')\n",
    "data2 = np.array(data2)\n",
    "data1 = DataFrame(data1)\n",
    "data2 = DataFrame(data2)\n",
    "\n",
    "pd_data_normalized = pd.concat([data1,data2],axis=1)\n",
    "\n",
    "dataset = np.array(pd_data_normalized)\n",
    "dataset = dataset.astype(np.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pick data gruop via range of y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "556"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def dataPick(oriData, lowLmt, upLmt, idx_y=207):\n",
    "    result = oriData[oriData[:,idx_y]<upLmt,:]\n",
    "    result = result[result[:,idx_y]>=lowLmt,:]\n",
    "    return result\n",
    "\n",
    "dataPick(dataset, 350, 100000).shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sepTrainX(dataset, percentage=0.9):\n",
    "    train = dataset[:np.trunc(len(dataset)*percentage).astype(np.int)]\n",
    "    test = dataset[np.trunc(len(dataset)*percentage).astype(np.int):]\n",
    "    return train, test\n",
    "\n",
    "def sepXY(dataset, feature_dim, percentage=0.9):   \n",
    "    traindata = dataset[:np.trunc(len(dataset)*percentage).astype(np.int)]\n",
    "    testdata = dataset[np.trunc(len(dataset)*percentage).astype(np.int):]\n",
    "    x_train = traindata[:,0:feature_dim]\n",
    "    y_train = traindata[:,feature_dim:]\n",
    "    x_test = testdata[:,0:feature_dim]\n",
    "    y_test = testdata[:,feature_dim:]\n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set class tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Amt2Cat(amount, keys, numClasses):\n",
    "    result = []\n",
    "    for i in amount:\n",
    "        y_class = 0\n",
    "        for j in keys:\n",
    "            if i<j:\n",
    "                result = np.append(result,[y_class],0)\n",
    "                break\n",
    "            y_class = y_class+1\n",
    "            if y_class == numClasses-1:\n",
    "                result = np.append(result,[y_class],0)\n",
    "                break\n",
    "    result = np_utils.to_categorical(result.astype(np.int), num_classes=numClasses)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set evlu  func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall(y_true, y_pred):\n",
    "    \"\"\"Recall metric.\n",
    "\n",
    "    Only computes a batch-wise average of recall.\n",
    "\n",
    "    Computes the recall, a metric for multi-label classification of\n",
    "    how many relevant items are selected.\n",
    "    \"\"\"\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    return true_positives / (possible_positives + K.epsilon())\n",
    "\n",
    "    \n",
    "def precision(y_true, y_pred):\n",
    "    \"\"\"Precision metric.\n",
    "\n",
    "    Only computes a batch-wise average of precision.\n",
    "\n",
    "    Computes the precision, a metric for multi-label classification of\n",
    "    how many selected items are relevant.\n",
    "    \"\"\"\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    return true_positives / (predicted_positives + K.epsilon())\n",
    "    \n",
    "def f1(y_true, y_pred):\n",
    "    \"\"\"true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))    \n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\"\"\"\n",
    "    myprecision = precision(y_true, y_pred)\n",
    "    myrecall = recall(y_true, y_pred)\n",
    "    return 2*((myprecision*myrecall)/(myprecision+myrecall+K.epsilon()))\n",
    "\n",
    "def tp(y_true, y_pred):\n",
    "    return K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "\n",
    "def fp(y_true, y_pred):\n",
    "    return K.sum(K.round(K.clip(y_pred, 0, 1)))-K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "\n",
    "def fn(y_true, y_pred):\n",
    "    return K.sum(K.round(K.clip(y_true, 0, 1)))-K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Determine size of bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def setKeys(num_bins, data):\n",
    "    sorted_data = sorted(data,key = lambda data: data[feature_dim])\n",
    "    keys = []\n",
    "    total_size = data.shape[0]\n",
    "    left_size = total_size\n",
    "    used_size = 0\n",
    "    key = sorted_data[0][feature_dim]\n",
    "    last_key = sorted_data[0][feature_dim]\n",
    "    for num in range(0, num_bins-1):\n",
    "        critical_size = left_size//(num_bins-num)\n",
    "        key = sorted_data[used_size+critical_size][feature_dim]+1\n",
    "        used_size = used_size + dataPick(dataset, last_key, key).shape[0]\n",
    "        left_size = total_size - used_size\n",
    "        last_key = key\n",
    "        keys.append(key)\n",
    "    return keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SA>=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setModel(num_bins):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(256, input_dim=feature_dim, activation='relu')) \n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Dense(512, activation='relu')) \n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Dense(256, activation='relu')) \n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Dense(num_bins, activation='softmax')) \n",
    "\n",
    "    # Define your optimizer\n",
    "    rmsprop = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=rmsprop, metrics=['accuracy',\n",
    "                                                                               recall, precision, f1])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_dim = 207\n",
    "\n",
    "# Set range of data\n",
    "data = dataPick(dataset, 0, 100000)\n",
    "\n",
    "# Seperate x and y  from dataset\n",
    "x_train, y_train, x_test, y_test = sepXY(data, feature_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting ------------\n",
      "number of bins is 2 \n",
      "keys is [1.0]\n",
      "Training -----------\n",
      "Epoch 1/1\n",
      "142593/142593 [==============================] - 72s 503us/step - loss: 0.6865 - acc: 0.5922 - recall: 0.5922 - precision: 0.5922 - f1: 0.5922\n",
      "\n",
      "Testing ------------\n",
      "15844/15844 [==============================] - 2s 117us/step\n",
      "test loss:  0.7051001404250282\n",
      "test accuracy:  0.5651981861068877\n",
      "recall:  0.5651981861068877\n",
      "precision:  0.5651981861068877\n",
      "f1: 0.5651981473435539\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Setting ------------\n",
      "number of bins is 3 \n",
      "keys is [1.0, 6.0]\n",
      "Training -----------\n",
      "Epoch 1/1\n",
      "142593/142593 [==============================] - 78s 548us/step - loss: 0.9874 - acc: 0.5762 - recall: 0.4122 - precision: 0.6293 - f1: 0.4865\n",
      "\n",
      "Testing ------------\n",
      "15844/15844 [==============================] - 2s 125us/step\n",
      "test loss:  1.1664774194900527\n",
      "test accuracy:  0.5044180799761872\n",
      "recall:  0.3908735214394245\n",
      "precision:  0.625964265729601\n",
      "f1: 0.46385625203870606\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for num_bins in range(2,4):\n",
    "    accuracys=[]\n",
    "    keys = setKeys(num_bins, data)\n",
    "    print('Setting ------------')\n",
    "    print('number of bins is', num_bins, '\\nkeys is', keys)\n",
    "    y_train_class = Amt2Cat(y_train, keys, num_bins)\n",
    "    y_test_class = Amt2Cat(y_test, keys, num_bins)\n",
    "    \n",
    "    # training & testing\n",
    "    print('Training -----------')\n",
    "    model = setModel(num_bins)\n",
    "    model.fit(x_train, y_train_class, epochs=1, batch_size = 10)\n",
    "    \n",
    "    print('\\nTesting ------------')\n",
    "    loss, accuracy, testrecall, testprecision, testf1 = model.evaluate(x_test, y_test_class, batch_size=10)\n",
    "    print('test loss: ', loss)\n",
    "    print('test accuracy: ', accuracy)\n",
    "    print('recall: ', testrecall)\n",
    "    print('precision: ', testprecision)\n",
    "    print('f1:', testf1)\n",
    "    print('\\n\\n\\n\\n')\n",
    "    accuracys.append(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5044180799761872]"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
