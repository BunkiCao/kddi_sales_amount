{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas import Series, DataFrame\n",
    "from sklearn.decomposition import PCA \n",
    "from sklearn.preprocessing import normalize\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import RMSprop\n",
    "from keras import backend as K\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data\n",
    "\n",
    "dataset is [datax, datay]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "datax = pd.read_csv('../feature.csv', sep='\\t')\n",
    "datay = pd.read_csv('output_y.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# merge x and y, and drop NA\n",
    "pd_data = pd.concat([datax,datay],axis=1)\n",
    "pd_data = pd_data.dropna(axis=0, how='any') \n",
    "#Remove bad data\n",
    "pd_data = pd_data[~pd_data['discount_rate'].isin(['販売価格'])]\n",
    "pd_data = pd_data[~pd_data['discount_rate'].isin(['ダミー'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = pd_data[['deal_category_cd','shop_id','deal_type_cd','deal_price','discount_rate','month','duration_days']]\n",
    "data2 = pd_data.drop(['deal_category_cd','shop_id','deal_type_cd','deal_price','discount_rate','month','duration_days'], axis=1)\n",
    "data1 = normalize(data1, axis=0, norm='max')\n",
    "data2 = np.array(data2)\n",
    "data1 = DataFrame(data1)\n",
    "data2 = DataFrame(data2)\n",
    "\n",
    "pd_data_normalized = pd.concat([data1,data2],axis=1)\n",
    "\n",
    "dataset = np.array(pd_data_normalized)\n",
    "dataset = dataset.astype(np.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pick data gruop via range of y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataPick(oriData, lowLmt, upLmt, idx_y=207):\n",
    "    result = oriData[oriData[:,idx_y]<upLmt,:]\n",
    "    result = result[result[:,idx_y]>=lowLmt,:]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "556"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataPick(dataset, 350, 100000).shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sepXY(dataset, feature_dim, percentage=0.9):   \n",
    "    traindata = dataset[:np.trunc(len(dataset)*percentage).astype(np.int)]\n",
    "    testdata = dataset[np.trunc(len(dataset)*percentage).astype(np.int):]\n",
    "    x_train = traindata[:,0:feature_dim]\n",
    "    y_train = traindata[:,feature_dim:]\n",
    "    x_test = testdata[:,0:feature_dim]\n",
    "    y_test = testdata[:,feature_dim:]\n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set class tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def biCat(amount,key):\n",
    "    result = []\n",
    "    for i in amount:\n",
    "        if i<key:\n",
    "            result = np.append(result,[0],0)\n",
    "#        elif i>0 and i<200:\n",
    "#            result = np.append(result,[1],0)\n",
    "        else:\n",
    "            result = np.append(result,[1],0)\n",
    "    result = result.reshape(-1,1)\n",
    "    result = result.astype(np.int)\n",
    "    result = np_utils.to_categorical(result, num_classes=2)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Amt2Cat(amount, keys, numClasses):\n",
    "    result = []\n",
    "    for i in amount:\n",
    "        y_class = 0\n",
    "        for j in keys:\n",
    "            if i<j:\n",
    "                result = np.append(result,[y_class],0)\n",
    "                break\n",
    "            y_class = y_class+1\n",
    "            if y_class == numClasses-1:\n",
    "                result = np.append(result,[y_class],0)\n",
    "                break\n",
    "    result = np_utils.to_categorical(result.astype(np.int), num_classes=numClasses)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall(y_true, y_pred):\n",
    "    \"\"\"Recall metric.\n",
    "\n",
    "    Only computes a batch-wise average of recall.\n",
    "\n",
    "    Computes the recall, a metric for multi-label classification of\n",
    "    how many relevant items are selected.\n",
    "    \"\"\"\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    return true_positives / (possible_positives + K.epsilon())\n",
    "\n",
    "    \n",
    "def precision(y_true, y_pred):\n",
    "    \"\"\"Precision metric.\n",
    "\n",
    "    Only computes a batch-wise average of precision.\n",
    "\n",
    "    Computes the precision, a metric for multi-label classification of\n",
    "    how many selected items are relevant.\n",
    "    \"\"\"\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    return true_positives / (predicted_positives + K.epsilon())\n",
    "    \n",
    "def f1(y_true, y_pred):\n",
    "    \"\"\"true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))    \n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\"\"\"\n",
    "    myprecision = precision(y_true, y_pred)\n",
    "    myrecall = recall(y_true, y_pred)\n",
    "    return 2*((myprecision*myrecall)/(myprecision+myrecall+K.epsilon()))\n",
    "\n",
    "def tp(y_true, y_pred):\n",
    "    return K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "\n",
    "def fp(y_true, y_pred):\n",
    "    return K.sum(K.round(K.clip(y_pred, 0, 1)))-K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "\n",
    "def fn(y_true, y_pred):\n",
    "    return K.sum(K.round(K.clip(y_true, 0, 1)))-K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traning and testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  >100, 10 classes\n",
    "### Pick data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "feature_dim = 207\n",
    "\n",
    "# Set range of data\n",
    "data = dataPick(dataset, 100, 1000000)\n",
    "\n",
    "# Seperate x and y  from dataset\n",
    "x_train, y_train, x_test, y_test = sepXY(data, feature_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set bins of y\n",
    "keys=[110,120,130,140,160,190,250,350,500]\n",
    "\n",
    "# Generate tags of y\n",
    "y_train_class = Amt2Cat(y_train, keys, 10)\n",
    "y_test_class = Amt2Cat(y_test, keys, 10)\n",
    "#y_train_class = biCat(y_train, 200)\n",
    "#y_test_class = biCat(y_test, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[309, 247, 250, 206, 272, 342, 343, 340, 191, 291]\n",
      "2791\n"
     ]
    }
   ],
   "source": [
    "counter = [0,0,0,0,0,0,0,0,0,0]\n",
    "c = 0\n",
    "for i in y_train:\n",
    "    y_class = 0\n",
    "    for j in keys:\n",
    "        if i<j:\n",
    "            counter[y_class] = counter[y_class]+1\n",
    "            break\n",
    "        y_class = y_class+1\n",
    "        if y_class == 9:\n",
    "            counter[y_class] = counter[y_class]+1\n",
    "            break\n",
    "    c=c+1\n",
    "print(counter)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[31, 21, 16, 12, 37, 43, 41, 36, 25, 49]\n",
      "311\n"
     ]
    }
   ],
   "source": [
    "counter = [0,0,0,0,0,0,0,0,0,0]\n",
    "c=0\n",
    "for i in y_test:\n",
    "    y_class = 0\n",
    "    for j in keys:\n",
    "        if i<j:\n",
    "            counter[y_class] = counter[y_class]+1\n",
    "            break\n",
    "        y_class = y_class+1\n",
    "        if y_class == 9:\n",
    "            counter[y_class] = counter[y_class]+1\n",
    "            break\n",
    "    c=c+1\n",
    "print(counter)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1078"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataPick(dataset, 140, 250).shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build model and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setModel():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(256, input_dim=feature_dim, activation='relu')) \n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Dense(512, activation='relu')) \n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Dense(256, activation='relu')) \n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Dense(10, activation='softmax')) \n",
    "\n",
    "    # Define your optimizer\n",
    "    rmsprop = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=rmsprop, metrics=['accuracy',\n",
    "                                                                               recall, precision, f1])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training -----------\n",
      "Epoch 1/15\n",
      "2791/2791 [==============================] - 1s 402us/step - loss: 2.2577 - acc: 0.1501 - recall: 0.0222 - precision: 0.1845 - f1: 0.0392\n",
      "Epoch 2/15\n",
      "2791/2791 [==============================] - 1s 345us/step - loss: 2.2121 - acc: 0.1713 - recall: 0.0387 - precision: 0.3081 - f1: 0.0676\n",
      "Epoch 3/15\n",
      "2791/2791 [==============================] - 1s 350us/step - loss: 2.1971 - acc: 0.1781 - recall: 0.0376 - precision: 0.3040 - f1: 0.0662\n",
      "Epoch 4/15\n",
      "2791/2791 [==============================] - 1s 356us/step - loss: 2.1855 - acc: 0.1831 - recall: 0.0405 - precision: 0.3440 - f1: 0.0717\n",
      "Epoch 5/15\n",
      "2791/2791 [==============================] - 1s 368us/step - loss: 2.1831 - acc: 0.1888 - recall: 0.0426 - precision: 0.3392 - f1: 0.0747\n",
      "Epoch 6/15\n",
      "2791/2791 [==============================] - 1s 352us/step - loss: 2.1636 - acc: 0.1981 - recall: 0.0423 - precision: 0.3368 - f1: 0.0741\n",
      "Epoch 7/15\n",
      "2791/2791 [==============================] - 1s 360us/step - loss: 2.1576 - acc: 0.1956 - recall: 0.0423 - precision: 0.3678 - f1: 0.0751\n",
      "Epoch 8/15\n",
      "2791/2791 [==============================] - 1s 364us/step - loss: 2.1536 - acc: 0.2021 - recall: 0.0462 - precision: 0.3472 - f1: 0.0802\n",
      "Epoch 9/15\n",
      "2791/2791 [==============================] - 1s 359us/step - loss: 2.1490 - acc: 0.2071 - recall: 0.0444 - precision: 0.3601 - f1: 0.0779\n",
      "Epoch 10/15\n",
      "2791/2791 [==============================] - 1s 347us/step - loss: 2.1271 - acc: 0.2103 - recall: 0.0498 - precision: 0.3738 - f1: 0.0863\n",
      "Epoch 11/15\n",
      "2791/2791 [==============================] - 1s 365us/step - loss: 2.1163 - acc: 0.2247 - recall: 0.0509 - precision: 0.3798 - f1: 0.0879\n",
      "Epoch 12/15\n",
      "2791/2791 [==============================] - 1s 359us/step - loss: 2.0946 - acc: 0.2264 - recall: 0.0559 - precision: 0.4085 - f1: 0.0964\n",
      "Epoch 13/15\n",
      "2791/2791 [==============================] - 1s 358us/step - loss: 2.0851 - acc: 0.2383 - recall: 0.0602 - precision: 0.4419 - f1: 0.1043\n",
      "Epoch 14/15\n",
      "2791/2791 [==============================] - 1s 394us/step - loss: 2.0886 - acc: 0.2418 - recall: 0.0588 - precision: 0.4092 - f1: 0.1004\n",
      "Epoch 15/15\n",
      "2791/2791 [==============================] - 1s 386us/step - loss: 2.0722 - acc: 0.2562 - recall: 0.0613 - precision: 0.3968 - f1: 0.1034\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9ca465fb00>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training\n",
    "print('Training -----------')\n",
    "model = setModel()\n",
    "model.fit(x_train, y_train_class, epochs=15, batch_size = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing ------------\n",
      "311/311 [==============================] - 0s 226us/step\n",
      "test loss:  2.295408232419054\n",
      "test accuracy:  0.19614148226198277\n",
      "recall:  0.0739549845457077\n",
      "precision:  0.3670953650183233\n",
      "f1: 0.11251404354426639\n"
     ]
    }
   ],
   "source": [
    "print('\\nTesting ------------')\n",
    "loss, accuracy, testrecall, testprecision, testf1 = model.evaluate(x_test, y_test_class, batch_size=10)\n",
    "\n",
    "print('test loss: ', loss)\n",
    "print('test accuracy: ', accuracy)\n",
    "print('recall: ', testrecall)\n",
    "print('precision: ', testprecision)\n",
    "print('f1:', testf1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  >100, 5 classes\n",
    "\n",
    "### Pick data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_dim = 207\n",
    "\n",
    "# Set range of data\n",
    "data = dataPick(dataset, 100, 1000000)\n",
    "\n",
    "# Seperate x and y  from dataset\n",
    "x_train, y_train, x_test, y_test = sepXY(data, feature_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set bins of y\n",
    "keys=[120,150,200,350]\n",
    "\n",
    "# Generate tags of y\n",
    "y_train_class = Amt2Cat(y_train, keys, 5)\n",
    "y_test_class = Amt2Cat(y_test, keys, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "608"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataPick(data, 100, 120).shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build model and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setModel():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(256, input_dim=feature_dim, activation='relu')) \n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Dense(512, activation='relu')) \n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Dense(256, activation='relu')) \n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Dense(5, activation='softmax')) \n",
    "\n",
    "    # Define your optimizer\n",
    "    rmsprop = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=rmsprop, metrics=['accuracy',\n",
    "                                                                               recall, precision, f1])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training -----------\n",
      "Epoch 1/5\n",
      "2791/2791 [==============================] - 1s 427us/step - loss: 1.5941 - acc: 0.2411 - recall: 0.0219 - precision: 0.1811 - f1: 0.0382\n",
      "Epoch 2/5\n",
      "2791/2791 [==============================] - 1s 337us/step - loss: 1.5481 - acc: 0.2641 - recall: 0.0408 - precision: 0.3440 - f1: 0.0721\n",
      "Epoch 3/5\n",
      "2791/2791 [==============================] - 1s 337us/step - loss: 1.5345 - acc: 0.2884 - recall: 0.0444 - precision: 0.3556 - f1: 0.0776\n",
      "Epoch 4/5\n",
      "2791/2791 [==============================] - 1s 345us/step - loss: 1.5269 - acc: 0.2859 - recall: 0.0462 - precision: 0.3732 - f1: 0.0811\n",
      "Epoch 5/5\n",
      "2791/2791 [==============================] - 1s 365us/step - loss: 1.5195 - acc: 0.2977 - recall: 0.0480 - precision: 0.3607 - f1: 0.0831\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9ca4870320>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training\n",
    "print('Training -----------')\n",
    "model = setModel()\n",
    "model.fit(x_train, y_train_class, epochs=5, batch_size = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing ------------\n",
      "311/311 [==============================] - 0s 281us/step\n",
      "test loss:  1.5534871812802036\n",
      "test accuracy:  0.2990353732726198\n",
      "recall:  0.07073955041419272\n",
      "precision:  0.3590567798093201\n",
      "f1: 0.10821502164629111\n"
     ]
    }
   ],
   "source": [
    "print('\\nTesting ------------')\n",
    "loss, accuracy, testrecall, testprecision, testf1 = model.evaluate(x_test, y_test_class, batch_size=10)\n",
    "\n",
    "print('test loss: ', loss)\n",
    "print('test accuracy: ', accuracy)\n",
    "print('recall: ', testrecall)\n",
    "print('precision: ', testprecision)\n",
    "print('f1:', testf1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  >100, 3 classes\n",
    "\n",
    "### Pick data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_dim = 207\n",
    "\n",
    "# Set range of data\n",
    "data = dataPick(dataset, 100, 1000000)\n",
    "\n",
    "# Seperate x and y  from dataset\n",
    "x_train, y_train, x_test, y_test = sepXY(data, feature_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set bins of y\n",
    "keys=[140,250]\n",
    "\n",
    "# Generate tags of y\n",
    "y_train_class = Amt2Cat(y_train, keys, 3)\n",
    "y_test_class = Amt2Cat(y_test, keys, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "608"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataPick(data, 100, 120).shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build model and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setModel():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(256, input_dim=feature_dim, activation='relu')) \n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Dense(512, activation='relu')) \n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Dense(256, activation='relu')) \n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Dense(3, activation='softmax')) \n",
    "\n",
    "    # Define your optimizer\n",
    "    rmsprop = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=rmsprop, metrics=['accuracy',\n",
    "                                                                               tp,fp,fn,recall,precision,f1])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training -----------\n",
      "Epoch 1/13\n",
      "2791/2791 [==============================] - 0s 176us/step - loss: 1.1099 - acc: 0.3791 - tp: 6.1204 - fp: 7.9412 - fn: 93.5862 - recall: 0.0613 - precision: 0.4031 - f1: 0.0926        \n",
      "Epoch 2/13\n",
      "2791/2791 [==============================] - 0s 57us/step - loss: 1.0549 - acc: 0.4292 - tp: 10.7327 - fp: 8.3744 - fn: 88.9738 - recall: 0.1075 - precision: 0.6518 - f1: 0.1689\n",
      "Epoch 3/13\n",
      "2791/2791 [==============================] - 0s 58us/step - loss: 1.0335 - acc: 0.4364 - tp: 9.3744 - fp: 5.1172 - fn: 90.3321 - recall: 0.0939 - precision: 0.7408 - f1: 0.1573\n",
      "Epoch 4/13\n",
      "2791/2791 [==============================] - 0s 57us/step - loss: 1.0270 - acc: 0.4493 - tp: 10.5210 - fp: 5.9445 - fn: 89.1856 - recall: 0.1053 - precision: 0.6819 - f1: 0.1739\n",
      "Epoch 5/13\n",
      "2791/2791 [==============================] - 0s 58us/step - loss: 1.0103 - acc: 0.4586 - tp: 13.5439 - fp: 7.0942 - fn: 86.1627 - recall: 0.1358 - precision: 0.7081 - f1: 0.2186\n",
      "Epoch 6/13\n",
      "2791/2791 [==============================] - 0s 58us/step - loss: 1.0041 - acc: 0.4586 - tp: 14.0684 - fp: 8.9642 - fn: 85.6381 - recall: 0.1412 - precision: 0.6662 - f1: 0.2237\n",
      "Epoch 7/13\n",
      "2791/2791 [==============================] - 0s 60us/step - loss: 0.9950 - acc: 0.4755 - tp: 16.0878 - fp: 9.6123 - fn: 83.6188 - recall: 0.1612 - precision: 0.6558 - f1: 0.2525\n",
      "Epoch 8/13\n",
      "2791/2791 [==============================] - 0s 59us/step - loss: 0.9797 - acc: 0.4941 - tp: 21.3386 - fp: 12.6578 - fn: 78.3680 - recall: 0.2139 - precision: 0.6642 - f1: 0.3115\n",
      "Epoch 9/13\n",
      "2791/2791 [==============================] - 0s 58us/step - loss: 0.9628 - acc: 0.5102 - tp: 23.3221 - fp: 13.6252 - fn: 76.3845 - recall: 0.2336 - precision: 0.6589 - f1: 0.3384\n",
      "Epoch 10/13\n",
      "2791/2791 [==============================] - 0s 58us/step - loss: 0.9534 - acc: 0.5109 - tp: 24.0817 - fp: 13.5471 - fn: 75.6249 - recall: 0.2418 - precision: 0.6627 - f1: 0.3460\n",
      "Epoch 11/13\n",
      "2791/2791 [==============================] - 0s 61us/step - loss: 0.9231 - acc: 0.5385 - tp: 30.0262 - fp: 17.2315 - fn: 69.6804 - recall: 0.3013 - precision: 0.6510 - f1: 0.4067\n",
      "Epoch 12/13\n",
      "2791/2791 [==============================] - 0s 59us/step - loss: 0.9134 - acc: 0.5496 - tp: 34.0813 - fp: 16.8108 - fn: 65.6252 - recall: 0.3418 - precision: 0.6772 - f1: 0.4498\n",
      "Epoch 13/13\n",
      "2791/2791 [==============================] - 0s 58us/step - loss: 0.9087 - acc: 0.5557 - tp: 32.7198 - fp: 17.8209 - fn: 66.9867 - recall: 0.3282 - precision: 0.6551 - f1: 0.4334\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f435218d358>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training\n",
    "print('Training -----------')\n",
    "model = setModel()\n",
    "model.fit(x_train, y_train_class, epochs=13, batch_size = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing ------------\n",
      "311/311 [==============================] - 0s 494us/step\n",
      "test loss:  1.1543410058190202\n",
      "test accuracy:  0.45659164322534174\n",
      "recall:  0.24437299433053497\n",
      "precision:  0.4592104994982385\n",
      "f1: 0.31432108020475824\n"
     ]
    }
   ],
   "source": [
    "print('\\nTesting ------------')\n",
    "loss, accuracy, ttp, tfp, tfn,  testrecall, testprecision, testf1 = model.evaluate(x_test, y_test_class, batch_size=20)\n",
    "\n",
    "print('test loss: ', loss)\n",
    "print('test accuracy: ', accuracy)\n",
    "print('tp: ', ttp)\n",
    "print('fp: ', tfp)\n",
    "print('fn:', tfn)\n",
    "print('recall: ', testrecall)\n",
    "print('precision: ', testprecision)\n",
    "print('f1:', testf1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  <100, 0 or not"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pick data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "feature_dim = 207\n",
    "\n",
    "# Set range of data\n",
    "data = dataPick(dataset, 0, 100)\n",
    "\n",
    "# Seperate x and y  from dataset\n",
    "x_train, y_train, x_test, y_test = sepXY(data, feature_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(155335, 208)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set bins of y\n",
    "keys=[1]\n",
    "\n",
    "# Generate tags of y\n",
    "y_train_class = Amt2Cat(y_train, keys, 2)\n",
    "y_test_class = Amt2Cat(y_test, keys, 2)\n",
    "#y_train_class = biCat(y_train, 200)\n",
    "#y_test_class = biCat(y_test, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[83150, 56651]\n",
      "139801\n"
     ]
    }
   ],
   "source": [
    "counter = [0,0]\n",
    "c = 0\n",
    "for i in y_train:\n",
    "    y_class = 0\n",
    "    for j in keys:\n",
    "        if i<j:\n",
    "            counter[y_class] = counter[y_class]+1\n",
    "            break\n",
    "        y_class = y_class+1\n",
    "        if y_class == 1:\n",
    "            counter[y_class] = counter[y_class]+1\n",
    "            break\n",
    "    c=c+1\n",
    "print(counter)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7997, 7537]\n",
      "15534\n"
     ]
    }
   ],
   "source": [
    "counter = [0,0]\n",
    "c=0\n",
    "for i in y_test:\n",
    "    y_class = 0\n",
    "    for j in keys:\n",
    "        if i<j:\n",
    "            counter[y_class] = counter[y_class]+1\n",
    "            break\n",
    "        y_class = y_class+1\n",
    "        if y_class == 1:\n",
    "            counter[y_class] = counter[y_class]+1\n",
    "            break\n",
    "    c=c+1\n",
    "print(counter)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build model and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setModel():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(256, input_dim=feature_dim, activation='relu')) \n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Dense(512, activation='relu')) \n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Dense(512, activation='relu')) \n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Dense(256, activation='relu')) \n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Dense(2, activation='softmax')) \n",
    "\n",
    "    # Define your optimizer\n",
    "    rmsprop = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=rmsprop, metrics=['accuracy',\n",
    "                                                                               tp, fp, fn])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training -----------\n",
      "Epoch 1/7\n",
      "139801/139801 [==============================] - 13s 94us/step - loss: 0.6366 - acc: 0.6119 - tp: 61.1906 - fp: 38.8087 - fn: 38.8087\n",
      "Epoch 2/7\n",
      "139801/139801 [==============================] - 13s 91us/step - loss: 0.6278 - acc: 0.6320 - tp: 63.1963 - fp: 36.8030 - fn: 36.8030\n",
      "Epoch 3/7\n",
      "139801/139801 [==============================] - 13s 92us/step - loss: 0.6234 - acc: 0.6394 - tp: 63.9395 - fp: 36.0598 - fn: 36.0598\n",
      "Epoch 4/7\n",
      "139801/139801 [==============================] - 13s 91us/step - loss: 0.6210 - acc: 0.6415 - tp: 64.1498 - fp: 35.8495 - fn: 35.8495\n",
      "Epoch 5/7\n",
      "139801/139801 [==============================] - 13s 93us/step - loss: 0.6181 - acc: 0.6483 - tp: 64.8307 - fp: 35.1686 - fn: 35.1686\n",
      "Epoch 6/7\n",
      "139801/139801 [==============================] - 13s 93us/step - loss: 0.6159 - acc: 0.6500 - tp: 65.0038 - fp: 34.9955 - fn: 34.9955\n",
      "Epoch 7/7\n",
      "139801/139801 [==============================] - 13s 93us/step - loss: 0.6154 - acc: 0.6528 - tp: 65.2821 - fp: 34.7172 - fn: 34.7172\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f43817da5f8>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training\n",
    "print('Training -----------')\n",
    "model = setModel()\n",
    "model.fit(x_train, y_train_class, epochs=7, batch_size = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing ------------\n",
      "15534/15534 [==============================] - 2s 107us/step\n",
      "test loss:  0.6798461425910158\n",
      "test accuracy:  0.5361787086721782\n",
      "tp:  5.360628299214626\n",
      "fp:  4.637826702716621\n",
      "fn: 4.637826702716621\n"
     ]
    }
   ],
   "source": [
    "print('\\nTesting ------------')\n",
    "loss, accuracy, testtp, testfp, testfn = model.evaluate(x_test, y_test_class, batch_size=10)\n",
    "\n",
    "print('test loss: ', loss)\n",
    "print('test accuracy: ', accuracy)\n",
    "print('tp: ', testtp)\n",
    "print('fp: ', testfp)\n",
    "print('fn:', testfn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  <100, 3 classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pick data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataPick' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-efac50613308>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Set range of data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataPick\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Seperate x and y  from dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dataPick' is not defined"
     ]
    }
   ],
   "source": [
    "feature_dim = 207\n",
    "\n",
    "# Set range of data\n",
    "data = dataPick(dataset, 0, 100)\n",
    "\n",
    "# Seperate x and y  from dataset\n",
    "x_train, y_train, x_test, y_test = sepXY(data, feature_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(155335, 208)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set bins of y\n",
    "keys=[1,10]\n",
    "\n",
    "# Generate tags of y\n",
    "y_train_class = Amt2Cat(y_train, keys, 3)\n",
    "y_test_class = Amt2Cat(y_test, keys, 3)\n",
    "#y_train_class = biCat(y_train, 200)\n",
    "#y_test_class = biCat(y_test, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[83150, 37244, 19407]\n",
      "139801\n"
     ]
    }
   ],
   "source": [
    "counter = [0,0,0]\n",
    "c = 0\n",
    "for i in y_train:\n",
    "    y_class = 0\n",
    "    for j in keys:\n",
    "        if i<j:\n",
    "            counter[y_class] = counter[y_class]+1\n",
    "            break\n",
    "        y_class = y_class+1\n",
    "        if y_class == 2:\n",
    "            counter[y_class] = counter[y_class]+1\n",
    "            break\n",
    "    c=c+1\n",
    "print(counter)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7997, 5325, 2212]\n",
      "15534\n"
     ]
    }
   ],
   "source": [
    "counter = [0,0,0]\n",
    "c=0\n",
    "for i in y_test:\n",
    "    y_class = 0\n",
    "    for j in keys:\n",
    "        if i<j:\n",
    "            counter[y_class] = counter[y_class]+1\n",
    "            break\n",
    "        y_class = y_class+1\n",
    "        if y_class == 2:\n",
    "            counter[y_class] = counter[y_class]+1\n",
    "            break\n",
    "    c=c+1\n",
    "print(counter)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37244\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "for i in y_train_class:\n",
    "    if i[1] == 1:\n",
    "        counter = counter + 1\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build model and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setModel():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(256, input_dim=feature_dim, activation='relu')) \n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Dense(512, activation='relu')) \n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Dense(256, activation='relu')) \n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Dense(3, activation='softmax')) \n",
    "\n",
    "    # Define your optimizer\n",
    "    rmsprop = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=rmsprop, metrics=['accuracy',\n",
    "                                                                               tp, precision, f1])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training -----------\n",
      "Epoch 1/5\n",
      "139801/139801 [==============================] - 27s 192us/step - loss: 0.8983 - acc: 0.5904 - recall: 0.4514 - precision: 0.6336 - f1: 0.5192\n",
      "Epoch 2/5\n",
      "139801/139801 [==============================] - 27s 194us/step - loss: 0.9212 - acc: 0.5899 - recall: 0.4677 - precision: 0.6287 - f1: 0.5318\n",
      "Epoch 3/5\n",
      "139801/139801 [==============================] - 27s 193us/step - loss: 0.9515 - acc: 0.5898 - recall: 0.4637 - precision: 0.6310 - f1: 0.5303\n",
      "Epoch 4/5\n",
      "139801/139801 [==============================] - 28s 197us/step - loss: 0.9570 - acc: 0.5905 - recall: 0.4678 - precision: 0.6304 - f1: 0.5332\n",
      "Epoch 5/5\n",
      "139801/139801 [==============================] - 29s 207us/step - loss: 0.9593 - acc: 0.5910 - recall: 0.4695 - precision: 0.6305 - f1: 0.5345\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9c2602e3c8>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training\n",
    "print('Training -----------')\n",
    "model = setModel()\n",
    "model.fit(x_train, y_train_class, epochs=5, batch_size = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing ------------\n",
      "15534/15534 [==============================] - 1s 69us/step\n",
      "test loss:  0.9843727154452413\n",
      "test accuracy:  0.5141624859075558\n",
      "recall:  0.379297030271174\n",
      "precision:  0.6440077183514669\n",
      "f1: 0.4571345203172536\n"
     ]
    }
   ],
   "source": [
    "print('\\nTesting ------------')\n",
    "loss, accuracy, testrecall, testprecision, testf1 = model.evaluate(x_test, y_test_class, batch_size=10)\n",
    "\n",
    "print('test loss: ', loss)\n",
    "print('test accuracy: ', accuracy)\n",
    "print('recall: ', testrecall)\n",
    "print('precision: ', testprecision)\n",
    "print('f1:', testf1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_dim = 207"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = dataset[:,0:207]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca=PCA(n_components=feature_dim)\n",
    "feature_pca=pca.fit_transform(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(158437, 208)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_pca = np.concatenate((feature_pca,dataset[:,207:208]),axis=1)\n",
    "dataset_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(67290, 208)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_pca_non_zero = dataset_pca[dataset_pca[:,feature_dim]!=0,:]\n",
    "dataset_pca_non_zero.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
