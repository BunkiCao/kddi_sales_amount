{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas import Series, DataFrame\n",
    "from sklearn.decomposition import PCA \n",
    "from sklearn.preprocessing import normalize\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import RMSprop\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data\n",
    "\n",
    "dataset is [datax, datay]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "datax = pd.read_csv('../feature.csv', sep='\\t')\n",
    "datay = pd.read_csv('output_y.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# merge x and y, and drop NA\n",
    "pd_data = pd.concat([datax,datay],axis=1)\n",
    "pd_data = pd_data.dropna(axis=0, how='any') \n",
    "#Remove bad data\n",
    "pd_data = pd_data[~pd_data['discount_rate'].isin(['販売価格'])]\n",
    "pd_data = pd_data[~pd_data['discount_rate'].isin(['ダミー'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = pd_data[['deal_category_cd','shop_id','deal_type_cd','deal_price','discount_rate','month','duration_days']]\n",
    "data2 = pd_data.drop(['deal_category_cd','shop_id','deal_type_cd','deal_price','discount_rate','month','duration_days'], axis=1)\n",
    "data1 = normalize(data1, axis=0, norm='max')\n",
    "data2 = np.array(data2)\n",
    "data1 = DataFrame(data1)\n",
    "data2 = DataFrame(data2)\n",
    "\n",
    "pd_data_normalized = pd.concat([data1,data2],axis=1)\n",
    "\n",
    "dataset = np.array(pd_data_normalized)\n",
    "dataset = dataset.astype(np.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pick data gruop via range of y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataPick(oriData, lowLmt, upLmt, idx_y=207):\n",
    "    result = oriData[oriData[:,idx_y]<upLmt,:]\n",
    "    result = result[result[:,idx_y]>=lowLmt,:]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "556"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataPick(dataset, 350, 100000).shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sepTrainX(dataset, percentage=0.9):\n",
    "    train = dataset[:np.trunc(len(dataset)*percentage).astype(np.int)]\n",
    "    test = dataset[np.trunc(len(dataset)*percentage).astype(np.int):]\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sepXY(dataset, feature_dim, percentage=0.9):   \n",
    "    traindata = dataset[:np.trunc(len(dataset)*percentage).astype(np.int)]\n",
    "    testdata = dataset[np.trunc(len(dataset)*percentage).astype(np.int):]\n",
    "    x_train = traindata[:,0:feature_dim]\n",
    "    y_train = traindata[:,feature_dim:]\n",
    "    x_test = testdata[:,0:feature_dim]\n",
    "    y_test = testdata[:,feature_dim:]\n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set class tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def biCat(amount,key):\n",
    "    result = []\n",
    "    for i in amount:\n",
    "        if i<key:\n",
    "            result = np.append(result,[0],0)\n",
    "#        elif i>0 and i<200:\n",
    "#            result = np.append(result,[1],0)\n",
    "        else:\n",
    "            result = np.append(result,[1],0)\n",
    "    result = result.reshape(-1,1)\n",
    "    result = result.astype(np.int)\n",
    "    result = np_utils.to_categorical(result, num_classes=2)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Amt2Cat(amount, keys, numClasses):\n",
    "    result = []\n",
    "    for i in amount:\n",
    "        y_class = 0\n",
    "        for j in keys:\n",
    "            if i<j:\n",
    "                result = np.append(result,[y_class],0)\n",
    "                break\n",
    "            y_class = y_class+1\n",
    "            if y_class == numClasses-1:\n",
    "                result = np.append(result,[y_class],0)\n",
    "                break\n",
    "    result = np_utils.to_categorical(result.astype(np.int), num_classes=numClasses)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traning and testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  >100, 10 classes\n",
    "### Pick data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "feature_dim = 207\n",
    "\n",
    "# Set range of data\n",
    "data = dataPick(dataset, 100, 1000000)\n",
    "\n",
    "# Seperate x and y  from dataset\n",
    "x_train, y_train, x_test, y_test = sepXY(data, feature_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set bins of y\n",
    "keys=[110,120,130,140,160,190,250,350,500]\n",
    "\n",
    "# Generate tags of y\n",
    "y_train_class = Amt2Cat(y_train, keys, 10)\n",
    "y_test_class = Amt2Cat(y_test, keys, 10)\n",
    "#y_train_class = biCat(y_train, 200)\n",
    "#y_test_class = biCat(y_test, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[309, 247, 250, 206, 272, 342, 343, 340, 191, 291]\n",
      "2791\n"
     ]
    }
   ],
   "source": [
    "counter = [0,0,0,0,0,0,0,0,0,0]\n",
    "c = 0\n",
    "for i in y_train:\n",
    "    y_class = 0\n",
    "    for j in keys:\n",
    "        if i<j:\n",
    "            counter[y_class] = counter[y_class]+1\n",
    "            break\n",
    "        y_class = y_class+1\n",
    "        if y_class == 9:\n",
    "            counter[y_class] = counter[y_class]+1\n",
    "            break\n",
    "    c=c+1\n",
    "print(counter)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[31, 21, 16, 12, 37, 43, 41, 36, 25, 49]\n",
      "311\n"
     ]
    }
   ],
   "source": [
    "counter = [0,0,0,0,0,0,0,0,0,0]\n",
    "c=0\n",
    "for i in y_test:\n",
    "    y_class = 0\n",
    "    for j in keys:\n",
    "        if i<j:\n",
    "            counter[y_class] = counter[y_class]+1\n",
    "            break\n",
    "        y_class = y_class+1\n",
    "        if y_class == 9:\n",
    "            counter[y_class] = counter[y_class]+1\n",
    "            break\n",
    "    c=c+1\n",
    "print(counter)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1078"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataPick(dataset, 140, 250).shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build model and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setModel():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(256, input_dim=feature_dim, activation='relu')) \n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Dense(512, activation='relu')) \n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Dense(256, activation='relu')) \n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Dense(10, activation='softmax')) \n",
    "\n",
    "    # Define your optimizer\n",
    "    rmsprop = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=rmsprop, metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training -----------\n",
      "Epoch 1/5\n",
      "2791/2791 [==============================] - 1s 481us/step - loss: 2.2644 - acc: 0.1523\n",
      "Epoch 2/5\n",
      "2791/2791 [==============================] - 1s 337us/step - loss: 2.2131 - acc: 0.1752\n",
      "Epoch 3/5\n",
      "2791/2791 [==============================] - 1s 338us/step - loss: 2.1971 - acc: 0.1813\n",
      "Epoch 4/5\n",
      "2791/2791 [==============================] - 1s 345us/step - loss: 2.1934 - acc: 0.1795\n",
      "Epoch 5/5\n",
      "2791/2791 [==============================] - 1s 338us/step - loss: 2.1783 - acc: 0.1942\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7f02022588>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training\n",
    "print('Training -----------')\n",
    "model = setModel()\n",
    "model.fit(x_train, y_train_class, epochs=5, batch_size = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing ------------\n",
      "311/311 [==============================] - 0s 452us/step\n",
      "test loss:  2.1832537459407204\n",
      "test accuracy:  0.22508038858317103\n"
     ]
    }
   ],
   "source": [
    "print('\\nTesting ------------')\n",
    "loss, accuracy = model.evaluate(x_test, y_test_class, batch_size=20)\n",
    "\n",
    "print('test loss: ', loss)\n",
    "print('test accuracy: ', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  >100, 5 classes\n",
    "\n",
    "### Pick data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_dim = 207\n",
    "\n",
    "# Set range of data\n",
    "data = dataPick(dataset, 100, 1000000)\n",
    "\n",
    "# Seperate x and y  from dataset\n",
    "x_train, y_train, x_test, y_test = sepXY(data, feature_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set bins of y\n",
    "keys=[120,150,200,350]\n",
    "\n",
    "# Generate tags of y\n",
    "y_train_class = Amt2Cat(y_train, keys, 5)\n",
    "y_test_class = Amt2Cat(y_test, keys, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "608"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataPick(data, 100, 120).shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build model and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setModel():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(256, input_dim=feature_dim, activation='relu')) \n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Dense(512, activation='relu')) \n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Dense(256, activation='relu')) \n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Dense(5, activation='softmax')) \n",
    "\n",
    "    # Define your optimizer\n",
    "    rmsprop = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=rmsprop, metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training -----------\n",
      "Epoch 1/5\n",
      "2791/2791 [==============================] - 1s 484us/step - loss: 1.5849 - acc: 0.2616\n",
      "Epoch 2/5\n",
      "2791/2791 [==============================] - 1s 347us/step - loss: 1.5445 - acc: 0.2651\n",
      "Epoch 3/5\n",
      "2791/2791 [==============================] - 1s 345us/step - loss: 1.5367 - acc: 0.2870\n",
      "Epoch 4/5\n",
      "2791/2791 [==============================] - 1s 336us/step - loss: 1.5280 - acc: 0.2977\n",
      "Epoch 5/5\n",
      "2791/2791 [==============================] - 1s 344us/step - loss: 1.5249 - acc: 0.2988\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7ef18fb0b8>"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training\n",
    "print('Training -----------')\n",
    "model = setModel()\n",
    "model.fit(x_train, y_train_class, epochs=5, batch_size = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing ------------\n",
      "311/311 [==============================] - 0s 509us/step\n",
      "test loss:  1.5387168812215137\n",
      "test accuracy:  0.28617363631533654\n"
     ]
    }
   ],
   "source": [
    "print('\\nTesting ------------')\n",
    "loss, accuracy = model.evaluate(x_test, y_test_class, batch_size=20)\n",
    "\n",
    "print('test loss: ', loss)\n",
    "print('test accuracy: ', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  >100, 3 classes\n",
    "\n",
    "### Pick data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_dim = 207\n",
    "\n",
    "# Set range of data\n",
    "data = dataPick(dataset, 100, 1000000)\n",
    "\n",
    "# Seperate x and y  from dataset\n",
    "x_train, y_train, x_test, y_test = sepXY(data, feature_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set bins of y\n",
    "keys=[140,250]\n",
    "\n",
    "# Generate tags of y\n",
    "y_train_class = Amt2Cat(y_train, keys, 3)\n",
    "y_test_class = Amt2Cat(y_test, keys, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "608"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataPick(data, 100, 120).shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build model and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setModel():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(256, input_dim=feature_dim, activation='relu')) \n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Dense(512, activation='relu')) \n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Dense(256, activation='relu')) \n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Dense(3, activation='softmax')) \n",
    "\n",
    "    # Define your optimizer\n",
    "    rmsprop = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=rmsprop, metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training -----------\n",
      "Epoch 1/5\n",
      "2791/2791 [==============================] - 1s 510us/step - loss: 1.0905 - acc: 0.3970\n",
      "Epoch 2/5\n",
      "2791/2791 [==============================] - 1s 347us/step - loss: 1.0527 - acc: 0.3963\n",
      "Epoch 3/5\n",
      "2791/2791 [==============================] - 1s 346us/step - loss: 1.0456 - acc: 0.4368\n",
      "Epoch 4/5\n",
      "2791/2791 [==============================] - 1s 350us/step - loss: 1.0318 - acc: 0.4274\n",
      "Epoch 5/5\n",
      "2791/2791 [==============================] - 1s 350us/step - loss: 1.0292 - acc: 0.4260\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7ef1918c88>"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training\n",
    "print('Training -----------')\n",
    "model = setModel()\n",
    "model.fit(x_train, y_train_class, epochs=5, batch_size = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing ------------\n",
      "311/311 [==============================] - 0s 540us/step\n",
      "test loss:  1.0484810937255908\n",
      "test accuracy:  0.398713830295483\n"
     ]
    }
   ],
   "source": [
    "print('\\nTesting ------------')\n",
    "loss, accuracy = model.evaluate(x_test, y_test_class, batch_size=20)\n",
    "\n",
    "print('test loss: ', loss)\n",
    "print('test accuracy: ', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  <100, 0 or not"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pick data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "feature_dim = 207\n",
    "\n",
    "# Set range of data\n",
    "data = dataPick(dataset, 0, 100)\n",
    "\n",
    "# Seperate x and y  from dataset\n",
    "x_train, y_train, x_test, y_test = sepXY(data, feature_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(155335, 208)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set bins of y\n",
    "keys=[1]\n",
    "\n",
    "# Generate tags of y\n",
    "y_train_class = Amt2Cat(y_train, keys, 2)\n",
    "y_test_class = Amt2Cat(y_test, keys, 2)\n",
    "#y_train_class = biCat(y_train, 200)\n",
    "#y_test_class = biCat(y_test, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[83150, 56651]\n",
      "139801\n"
     ]
    }
   ],
   "source": [
    "counter = [0,0]\n",
    "c = 0\n",
    "for i in y_train:\n",
    "    y_class = 0\n",
    "    for j in keys:\n",
    "        if i<j:\n",
    "            counter[y_class] = counter[y_class]+1\n",
    "            break\n",
    "        y_class = y_class+1\n",
    "        if y_class == 1:\n",
    "            counter[y_class] = counter[y_class]+1\n",
    "            break\n",
    "    c=c+1\n",
    "print(counter)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7997, 7537]\n",
      "15534\n"
     ]
    }
   ],
   "source": [
    "counter = [0,0]\n",
    "c=0\n",
    "for i in y_test:\n",
    "    y_class = 0\n",
    "    for j in keys:\n",
    "        if i<j:\n",
    "            counter[y_class] = counter[y_class]+1\n",
    "            break\n",
    "        y_class = y_class+1\n",
    "        if y_class == 1:\n",
    "            counter[y_class] = counter[y_class]+1\n",
    "            break\n",
    "    c=c+1\n",
    "print(counter)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build model and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setModel():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(256, input_dim=feature_dim, activation='relu')) \n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Dense(512, activation='relu')) \n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Dense(256, activation='relu')) \n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Dense(2, activation='softmax')) \n",
    "\n",
    "    # Define your optimizer\n",
    "    rmsprop = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=rmsprop, metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training -----------\n",
      "Epoch 1/3\n",
      "139801/139801 [==============================] - 25s 178us/step - loss: 0.6581 - acc: 0.6046\n",
      "Epoch 2/3\n",
      "139801/139801 [==============================] - 25s 177us/step - loss: 0.6665 - acc: 0.6248\n",
      "Epoch 3/3\n",
      "139801/139801 [==============================] - 25s 177us/step - loss: 0.6743 - acc: 0.6310\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7faef5e46b70>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training\n",
    "print('Training -----------')\n",
    "model = setModel()\n",
    "model.fit(x_train, y_train_class, epochs=3, batch_size = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing ------------\n",
      "15534/15534 [==============================] - 0s 29us/step\n",
      "test loss:  0.685622415554152\n",
      "test accuracy:  0.6776104031951559\n"
     ]
    }
   ],
   "source": [
    "print('\\nTesting ------------')\n",
    "loss, accuracy = model.evaluate(x_test, y_test_class, batch_size=20)\n",
    "\n",
    "print('test loss: ', loss)\n",
    "print('test accuracy: ', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  <100, 3 classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pick data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "feature_dim = 207\n",
    "\n",
    "# Set range of data\n",
    "data = dataPick(dataset, 0, 100)\n",
    "\n",
    "# Seperate x and y  from dataset\n",
    "x_train, y_train, x_test, y_test = sepXY(data, feature_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(155335, 208)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set bins of y\n",
    "keys=[1,10]\n",
    "\n",
    "# Generate tags of y\n",
    "y_train_class = Amt2Cat(y_train, keys, 3)\n",
    "y_test_class = Amt2Cat(y_test, keys, 3)\n",
    "#y_train_class = biCat(y_train, 200)\n",
    "#y_test_class = biCat(y_test, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[83150, 37244, 19407]\n",
      "139801\n"
     ]
    }
   ],
   "source": [
    "counter = [0,0,0]\n",
    "c = 0\n",
    "for i in y_train:\n",
    "    y_class = 0\n",
    "    for j in keys:\n",
    "        if i<j:\n",
    "            counter[y_class] = counter[y_class]+1\n",
    "            break\n",
    "        y_class = y_class+1\n",
    "        if y_class == 2:\n",
    "            counter[y_class] = counter[y_class]+1\n",
    "            break\n",
    "    c=c+1\n",
    "print(counter)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7997, 5325, 2212]\n",
      "15534\n"
     ]
    }
   ],
   "source": [
    "counter = [0,0,0]\n",
    "c=0\n",
    "for i in y_test:\n",
    "    y_class = 0\n",
    "    for j in keys:\n",
    "        if i<j:\n",
    "            counter[y_class] = counter[y_class]+1\n",
    "            break\n",
    "        y_class = y_class+1\n",
    "        if y_class == 2:\n",
    "            counter[y_class] = counter[y_class]+1\n",
    "            break\n",
    "    c=c+1\n",
    "print(counter)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37244\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "for i in y_train_class:\n",
    "    if i[1] == 1:\n",
    "        counter = counter + 1\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build model and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setModel():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(256, input_dim=feature_dim, activation='relu')) \n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Dense(512, activation='relu')) \n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Dense(256, activation='relu')) \n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Dense(3, activation='softmax')) \n",
    "\n",
    "    # Define your optimizer\n",
    "    rmsprop = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=rmsprop, metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training -----------\n",
      "Epoch 1/2\n",
      "139801/139801 [==============================] - 28s 199us/step - loss: 0.8971 - acc: 0.5905\n",
      "Epoch 2/2\n",
      "139801/139801 [==============================] - 27s 190us/step - loss: 0.9308 - acc: 0.5891\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7faef5f00c18>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training\n",
    "print('Training -----------')\n",
    "model = setModel()\n",
    "model.fit(x_train, y_train_class, epochs=2, batch_size = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing ------------\n",
      "15534/15534 [==============================] - 1s 39us/step\n",
      "test loss:  0.944731870511175\n",
      "test accuracy:  0.5189906014133117\n"
     ]
    }
   ],
   "source": [
    "print('\\nTesting ------------')\n",
    "loss, accuracy = model.evaluate(x_test, y_test_class, batch_size=20)\n",
    "\n",
    "print('test loss: ', loss)\n",
    "print('test accuracy: ', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_dim = 207"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = dataset[:,0:207]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca=PCA(n_components=feature_dim)\n",
    "feature_pca=pca.fit_transform(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(158437, 208)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_pca = np.concatenate((feature_pca,dataset[:,207:208]),axis=1)\n",
    "dataset_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(67290, 208)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_pca_non_zero = dataset_pca[dataset_pca[:,feature_dim]!=0,:]\n",
    "dataset_pca_non_zero.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
